{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16bba040-b9e6-4132-84cc-dfdf6d9201be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\1.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\2.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\3.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\4.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\8.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\10.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\11.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\12.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\13.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\14.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\16.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\17.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\18.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\19.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\20.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\21.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\22.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\23.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\24.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\25.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\26.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\27.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\28.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\30.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\31.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\33.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\34.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\35.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\36.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\39.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\40.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\41.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\42.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\43.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\44.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\45.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\46.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\47.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\48.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\49.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\50.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\51.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\54.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\55.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\56.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\58.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\61.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\63.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\65.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\67.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\70.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\71.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\78.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\99.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\128.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\131.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\132.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\133.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\134.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\135.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\136.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\137.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\138.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\139.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\140.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\141.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\142.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\143.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\145.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\146.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\147.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\148.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\149.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\150.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\151.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\153.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\155.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\156.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\157.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\158.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\159.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\171.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\173.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\177.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\179.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\180.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\190.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\205.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\206.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\207.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\208.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\209.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\210.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\248.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\32446.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\32447.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37945.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37949.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37950.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37951.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37953.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37954.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37955.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37956.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37957.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37960.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37961.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37962.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37964.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37965.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37967.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37969.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37971.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37972.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37973.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37979.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37982.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37983.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37989.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37990.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37992.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37993.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37995.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37996.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37997.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\37998.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38000.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38001.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38002.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38003.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38012.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38013.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38015.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38016.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38017.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38018.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38019.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38020.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38021.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38022.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38024.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38030.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38031.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38039.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38044.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38045.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38064.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38069.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38072.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38073.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38074.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38075.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38076.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38077.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38079.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38080.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38081.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38082.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38084.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38090.csv\n",
      "File saved: C:\\Users\\ss6365\\Desktop\\Datasets\\UCI\\gps\\dataset_processed\\38092.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def split_csv_by_track_id(input_csv_path, output_folder_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    \n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "    \n",
    "    # Group by 'track_id' and write separate CSVs\n",
    "    for track_id, group_df in df.groupby('track_id'):\n",
    "        output_path = os.path.join(output_folder_path, f\"{track_id}.csv\")\n",
    "        group_df.to_csv(output_path, index=False)\n",
    "        print(f\"File saved: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "input_csv_path = 'C:\\\\Users\\\\ss6365\\\\Desktop\\\\Datasets\\\\UCI\\\\gps\\\\GPSTrajectory\\\\go_track_trackspoints.csv' # Update this path\n",
    "output_folder_path = 'C:\\\\Users\\\\ss6365\\\\Desktop\\\\Datasets\\\\UCI\\\\gps\\\\dataset_processed' # Update this path\n",
    "\n",
    "split_csv_by_track_id(input_csv_path, output_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff414884-25d0-44af-b323-c7bf835bd73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The earliest date of data logging is: 2014-09-13 07:24:32\n",
      "The latest date of data logging is: 2016-01-19 13:01:47\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = 'C:\\\\Users\\\\ss6365\\\\Desktop\\\\Datasets\\\\UCI\\\\gps\\\\GPSTrajectory\\\\go_track_trackspoints.csv'  # Update this path to your file's location\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert 'time' column to datetime without specifying the format\n",
    "df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "\n",
    "# Calculate the minimum and maximum dates in the 'time' column\n",
    "min_date = df['time'].min()\n",
    "max_date = df['time'].max()\n",
    "\n",
    "# Print the results\n",
    "print(f\"The earliest date of data logging is: {min_date}\")\n",
    "print(f\"The latest date of data logging is: {max_date}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b83d87d2-e83a-4116-a0ac-640abae74d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>track_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-10.939341</td>\n",
       "      <td>-37.062742</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-13 07:24:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-10.939341</td>\n",
       "      <td>-37.062742</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-13 07:24:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-10.939324</td>\n",
       "      <td>-37.062765</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-13 07:24:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-10.939211</td>\n",
       "      <td>-37.062843</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-13 07:24:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-10.938939</td>\n",
       "      <td>-37.062879</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-13 07:24:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18102</th>\n",
       "      <td>19565</td>\n",
       "      <td>-10.923722</td>\n",
       "      <td>-37.106579</td>\n",
       "      <td>38092</td>\n",
       "      <td>2016-01-19 13:01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18103</th>\n",
       "      <td>19566</td>\n",
       "      <td>-10.923704</td>\n",
       "      <td>-37.106693</td>\n",
       "      <td>38092</td>\n",
       "      <td>2016-01-19 13:01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18104</th>\n",
       "      <td>19567</td>\n",
       "      <td>-10.923715</td>\n",
       "      <td>-37.106688</td>\n",
       "      <td>38092</td>\n",
       "      <td>2016-01-19 13:01:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18105</th>\n",
       "      <td>19568</td>\n",
       "      <td>-10.923715</td>\n",
       "      <td>-37.106688</td>\n",
       "      <td>38092</td>\n",
       "      <td>2016-01-19 13:01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18106</th>\n",
       "      <td>19569</td>\n",
       "      <td>-10.923716</td>\n",
       "      <td>-37.106688</td>\n",
       "      <td>38092</td>\n",
       "      <td>2016-01-19 13:01:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18107 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   latitude  longitude  track_id                 time\n",
       "0          1 -10.939341 -37.062742         1  2014-09-13 07:24:32\n",
       "1          2 -10.939341 -37.062742         1  2014-09-13 07:24:37\n",
       "2          3 -10.939324 -37.062765         1  2014-09-13 07:24:42\n",
       "3          4 -10.939211 -37.062843         1  2014-09-13 07:24:47\n",
       "4          5 -10.938939 -37.062879         1  2014-09-13 07:24:53\n",
       "...      ...        ...        ...       ...                  ...\n",
       "18102  19565 -10.923722 -37.106579     38092  2016-01-19 13:01:01\n",
       "18103  19566 -10.923704 -37.106693     38092  2016-01-19 13:01:12\n",
       "18104  19567 -10.923715 -37.106688     38092  2016-01-19 13:01:24\n",
       "18105  19568 -10.923715 -37.106688     38092  2016-01-19 13:01:36\n",
       "18106  19569 -10.923716 -37.106688     38092  2016-01-19 13:01:47\n",
       "\n",
       "[18107 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c8cf26-6901-42df-95a5-6d8a5b1d782e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.9219998"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['latitude'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e08c47d3-5922-4a29-997f-a236bf75d44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-37.05778433"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['longitude'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50bcfbae-a4ff-4108-8fcc-22ab2a232b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap saved to C:\\Users\\ss6365\\Desktop\\AR_GPS_Sensor_Data\\map_uci.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Load your CSV file\n",
    "csv_file_path = 'C:\\\\Users\\\\ss6365\\\\Desktop\\\\Datasets\\\\UCI\\\\gps\\\\GPSTrajectory\\\\go_track_trackspoints.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Assuming your columns are named 'Latitude' and 'Longitude'\n",
    "latitude = 'latitude'\n",
    "longitude = 'longitude'\n",
    "\n",
    "# Create a map centered around the average location\n",
    "map_center = [df[latitude].mean(), df[longitude].mean()]\n",
    "m = folium.Map(location=map_center, zoom_start=10)\n",
    "\n",
    "# Create a HeatMap layer and add it to the map\n",
    "heat_data = [[row[latitude], row[longitude]] for index, row in df.iterrows()]\n",
    "HeatMap(heat_data).add_to(m)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "output_html = 'C:\\\\Users\\\\ss6365\\\\Desktop\\\\AR_GPS_Sensor_Data\\\\map_uci.html'\n",
    "m.save(output_html)\n",
    "\n",
    "print(f\"Heatmap saved to {output_html}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "766ac6b1-1bae-4d57-9087-1b6ce43a830c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Distance Traversed: 868.7213830764748 km\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance in kilometers between two points \n",
    "    on the earth (specified in decimal degrees).\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n",
    "\n",
    "def calculate_distance_for_file(csv_file):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Calculate the distances\n",
    "    distances = [\n",
    "        haversine(lon1, lat1, lon2, lat2) \n",
    "        for lat1, lon1, lat2, lon2 in zip(df['latitude'][:-1], df['longitude'][:-1], df['latitude'][1:], df['longitude'][1:])\n",
    "    ]\n",
    "    \n",
    "    # Sum the distances\n",
    "    return sum(distances)\n",
    "\n",
    "def calculate_cumulative_distance(directory):\n",
    "    total_distance = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            total_distance += calculate_distance_for_file(file_path)\n",
    "    return total_distance\n",
    "\n",
    "# Example usage\n",
    "directory = 'C:\\\\Users\\\\ss6365\\\\Desktop\\\\Datasets\\\\UCI\\\\gps\\\\dataset_processed'  # Replace this with the path to your directory\n",
    "cumulative_distance = calculate_cumulative_distance(directory)\n",
    "print(f\"Cumulative Distance Traversed: {cumulative_distance} km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07d806ce-b6f5-42f2-96cd-569903b3d6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Distance Traversed: 868.7213830764748 km\n",
      "Average Distance: 47.97710184329126 m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance in kilometers between two points \n",
    "    on the earth (specified in decimal degrees).\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r\n",
    "\n",
    "def calculate_distance_for_file(csv_file):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Calculate the distances\n",
    "    distances = [\n",
    "        haversine(lon1, lat1, lon2, lat2) \n",
    "        for lat1, lon1, lat2, lon2 in zip(df['latitude'][:-1], df['longitude'][:-1], df['latitude'][1:], df['longitude'][1:])\n",
    "    ]\n",
    "    \n",
    "    # Sum the distances\n",
    "    return sum(distances), len(df)\n",
    "\n",
    "def calculate_cumulative_distance_and_row_count(directory):\n",
    "    \n",
    "    total_distance = 0\n",
    "    total_row_count = 0\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            distance, row_count = calculate_distance_for_file(file_path)\n",
    "            total_distance += distance\n",
    "            total_row_count += row_count\n",
    "\n",
    "    average_distance =  (total_distance/ total_row_count)*1000\n",
    "    return total_distance, average_distance\n",
    "\n",
    "# Example usage\n",
    "directory = 'C:\\\\Users\\\\ss6365\\\\Desktop\\\\location_privacy_final\\\\uci\\\\data\\\\utility'  # Replace this with the path to your directory\n",
    "cumulative_distance, average_distance = calculate_cumulative_distance_and_row_count(directory)\n",
    "print(f\"Cumulative Distance Traversed: {cumulative_distance} km\")\n",
    "print(f\"Average Distance: {average_distance} m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06afd35b-395e-4d90-96e5-55648a8aca70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>track_id</th>\n",
       "      <th>time</th>\n",
       "      <th>time_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-10.939341</td>\n",
       "      <td>-37.062742</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-13 07:24:32</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-10.939341</td>\n",
       "      <td>-37.062742</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-13 07:24:37</td>\n",
       "      <td>0 days 00:00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-10.939324</td>\n",
       "      <td>-37.062765</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-13 07:24:42</td>\n",
       "      <td>0 days 00:00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-10.939211</td>\n",
       "      <td>-37.062843</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-13 07:24:47</td>\n",
       "      <td>0 days 00:00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-10.938939</td>\n",
       "      <td>-37.062879</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-13 07:24:53</td>\n",
       "      <td>0 days 00:00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   latitude  longitude  track_id                time       time_diff\n",
       "0   1 -10.939341 -37.062742         1 2014-09-13 07:24:32             NaT\n",
       "1   2 -10.939341 -37.062742         1 2014-09-13 07:24:37 0 days 00:00:05\n",
       "2   3 -10.939324 -37.062765         1 2014-09-13 07:24:42 0 days 00:00:05\n",
       "3   4 -10.939211 -37.062843         1 2014-09-13 07:24:47 0 days 00:00:05\n",
       "4   5 -10.938939 -37.062879         1 2014-09-13 07:24:53 0 days 00:00:06"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'C:\\\\Users\\\\ss6365\\\\Desktop\\\\Datasets\\\\UCI\\\\gps\\\\dataset_processed\\\\1.csv'  # Update this path to your file's location\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "df_new = pd.read_csv(file_path)\n",
    "\n",
    "# Convert 'time' column to datetime\n",
    "df_new['time'] = pd.to_datetime(df_new['time'])\n",
    "\n",
    "# Calculate the time differences (intervals) between consecutive rows\n",
    "df_new['time_diff'] = df_new['time'].diff()\n",
    "\n",
    "# Display the first few rows to see the 'time_diff' column\n",
    "df_new.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e539794-a5ec-49cf-8104-8bb3a6adc9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average sampling interval is: 5.573033707865169 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load your CSV\n",
    "file_path = 'C:\\\\Users\\\\ss6365\\\\Desktop\\\\Datasets\\\\UCI\\\\gps\\\\dataset_processed\\\\1.csv'  # Update this path to your file's location\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the 'time' column to datetime\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Ensure the data is sorted by 'time'\n",
    "df = df.sort_values(by='time')\n",
    "\n",
    "# Calculate differences (intervals) between each timestamp and the previous one\n",
    "df['sampling_interval'] = df['time'].diff()\n",
    "\n",
    "# Convert intervals to a consistent unit, e.g., seconds\n",
    "df['sampling_interval_seconds'] = df['sampling_interval'].dt.total_seconds()\n",
    "\n",
    "# Calculate the average sampling interval\n",
    "average_sampling_interval = df['sampling_interval_seconds'].mean()\n",
    "\n",
    "print(f\"The average sampling interval is: {average_sampling_interval} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70dcd8ae-982d-4a79-90fb-bbb241ac7639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.csv: 5.573033707865169 seconds\n",
      "10.csv: 5.0 seconds\n",
      "11.csv: 7.5514018691588785 seconds\n",
      "12.csv: 10.615384615384615 seconds\n",
      "128.csv: 10.422222222222222 seconds\n",
      "13.csv: 10.564245810055866 seconds\n",
      "131.csv: 5.791139240506329 seconds\n",
      "132.csv: 5.701408450704226 seconds\n",
      "133.csv: 5.720394736842105 seconds\n",
      "134.csv: 5.32013201320132 seconds\n",
      "135.csv: 5.32013201320132 seconds\n",
      "136.csv: 5.518518518518518 seconds\n",
      "137.csv: 5.518518518518518 seconds\n",
      "138.csv: 5.544117647058823 seconds\n",
      "139.csv: 5.544117647058823 seconds\n",
      "14.csv: Insufficient data for interval calculation seconds\n",
      "140.csv: 5.530612244897959 seconds\n",
      "141.csv: 5.530612244897959 seconds\n",
      "142.csv: 5.522875816993464 seconds\n",
      "143.csv: 5.522875816993464 seconds\n",
      "145.csv: 5.328947368421052 seconds\n",
      "146.csv: 5.5 seconds\n",
      "147.csv: 5.990430622009569 seconds\n",
      "148.csv: Insufficient data for interval calculation seconds\n",
      "149.csv: 6.186813186813187 seconds\n",
      "150.csv: 5.738938053097345 seconds\n",
      "151.csv: 5.547038327526132 seconds\n",
      "153.csv: 5.582089552238806 seconds\n",
      "155.csv: 10.0 seconds\n",
      "156.csv: 18.333333333333332 seconds\n",
      "157.csv: 30.25 seconds\n",
      "158.csv: 47.666666666666664 seconds\n",
      "159.csv: Insufficient data for interval calculation seconds\n",
      "16.csv: 5.553191489361702 seconds\n",
      "17.csv: 7.348571428571429 seconds\n",
      "171.csv: Insufficient data for interval calculation seconds\n",
      "173.csv: 5.428571428571429 seconds\n",
      "177.csv: 10.0 seconds\n",
      "179.csv: 10.0 seconds\n",
      "18.csv: 10.615384615384615 seconds\n",
      "180.csv: 5.466666666666667 seconds\n",
      "19.csv: 20.212389380530972 seconds\n",
      "190.csv: 6.0 seconds\n",
      "2.csv: 5.473214285714286 seconds\n",
      "20.csv: 5.49171270718232 seconds\n",
      "205.csv: 12.0 seconds\n",
      "206.csv: 7.571428571428571 seconds\n",
      "207.csv: 7.333333333333333 seconds\n",
      "208.csv: 6.616352201257862 seconds\n",
      "209.csv: 8.88888888888889 seconds\n",
      "21.csv: 5.49171270718232 seconds\n",
      "210.csv: 14.483333333333333 seconds\n",
      "22.csv: 5.6421052631578945 seconds\n",
      "23.csv: 5.550802139037433 seconds\n",
      "24.csv: 14.5 seconds\n",
      "248.csv: 14.125 seconds\n",
      "25.csv: 102.0 seconds\n",
      "26.csv: 17.485 seconds\n",
      "27.csv: 17.485 seconds\n",
      "28.csv: 5.685714285714286 seconds\n",
      "3.csv: 10.636363636363637 seconds\n",
      "30.csv: 5.550387596899225 seconds\n",
      "31.csv: 5.550387596899225 seconds\n",
      "32446.csv: 16.015625 seconds\n",
      "32447.csv: 16.015625 seconds\n",
      "33.csv: 10.646153846153846 seconds\n",
      "34.csv: 5.58 seconds\n",
      "35.csv: 5.631067961165049 seconds\n",
      "36.csv: 5.554216867469879 seconds\n",
      "37.csv: 5.584905660377358 seconds\n",
      "37945.csv: 15.21951219512195 seconds\n",
      "37949.csv: 12.0 seconds\n",
      "37950.csv: 15.035714285714286 seconds\n",
      "37951.csv: 15.035714285714286 seconds\n",
      "37953.csv: 13.59433962264151 seconds\n",
      "37954.csv: 13.59433962264151 seconds\n",
      "37955.csv: 13.721739130434782 seconds\n",
      "37956.csv: 8.548387096774194 seconds\n",
      "37957.csv: 8.137254901960784 seconds\n",
      "37960.csv: 12.02158273381295 seconds\n",
      "37961.csv: 312.4 seconds\n",
      "37962.csv: 7.689486552567237 seconds\n",
      "37964.csv: 13.142857142857142 seconds\n",
      "37965.csv: 38.64 seconds\n",
      "37967.csv: 11.48421052631579 seconds\n",
      "37969.csv: 12.418181818181818 seconds\n",
      "37971.csv: 10.0 seconds\n",
      "37972.csv: 10.0 seconds\n",
      "37973.csv: 6.333333333333333 seconds\n",
      "37979.csv: 11.5 seconds\n",
      "37982.csv: Insufficient data for interval calculation seconds\n",
      "37983.csv: 10.0 seconds\n",
      "37989.csv: 23.22641509433962 seconds\n",
      "37990.csv: Insufficient data for interval calculation seconds\n",
      "37992.csv: 8.106382978723405 seconds\n",
      "37993.csv: Insufficient data for interval calculation seconds\n",
      "37995.csv: 12.74468085106383 seconds\n",
      "37996.csv: 7.258555133079848 seconds\n",
      "37997.csv: 7.258555133079848 seconds\n",
      "37998.csv: Insufficient data for interval calculation seconds\n",
      "38.csv: 5.6395348837209305 seconds\n",
      "38000.csv: 11.742647058823529 seconds\n",
      "38001.csv: 14.035714285714286 seconds\n",
      "38002.csv: 7.489583333333333 seconds\n",
      "38003.csv: 9.331550802139038 seconds\n",
      "38012.csv: 6.850267379679145 seconds\n",
      "38013.csv: 6.651408450704225 seconds\n",
      "38015.csv: 14.886363636363637 seconds\n",
      "38016.csv: 11.98473282442748 seconds\n",
      "38017.csv: 7.010204081632653 seconds\n",
      "38018.csv: 12.0 seconds\n",
      "38019.csv: 6.7555555555555555 seconds\n",
      "38020.csv: 6.571428571428571 seconds\n",
      "38021.csv: 6.571428571428571 seconds\n",
      "38022.csv: 11.99047619047619 seconds\n",
      "38024.csv: 15.128205128205128 seconds\n",
      "38030.csv: Insufficient data for interval calculation seconds\n",
      "38031.csv: 14.095238095238095 seconds\n",
      "38039.csv: 12.0 seconds\n",
      "38044.csv: 11.591549295774648 seconds\n",
      "38045.csv: 12.0 seconds\n",
      "38064.csv: 12.32 seconds\n",
      "38069.csv: 11.75 seconds\n",
      "38072.csv: 6.815533980582524 seconds\n",
      "38073.csv: 7.093023255813954 seconds\n",
      "38074.csv: 6.73404255319149 seconds\n",
      "38075.csv: 6.822222222222222 seconds\n",
      "38076.csv: 6.922413793103448 seconds\n",
      "38077.csv: 6.885714285714286 seconds\n",
      "38079.csv: 6.911764705882353 seconds\n",
      "38080.csv: 6.642857142857143 seconds\n",
      "38081.csv: 6.454545454545454 seconds\n",
      "38082.csv: 6.7669172932330826 seconds\n",
      "38084.csv: 11.333333333333334 seconds\n",
      "38090.csv: 11.0 seconds\n",
      "38092.csv: 11.5 seconds\n",
      "39.csv: 10.330769230769231 seconds\n",
      "4.csv: 12.7421875 seconds\n",
      "40.csv: 10.825471698113208 seconds\n",
      "41.csv: 5.474537037037037 seconds\n",
      "42.csv: 5.4787234042553195 seconds\n",
      "43.csv: 5.975903614457831 seconds\n",
      "44.csv: 5.584905660377358 seconds\n",
      "45.csv: 5.584905660377358 seconds\n",
      "46.csv: 6.7889908256880735 seconds\n",
      "47.csv: 5.626126126126126 seconds\n",
      "48.csv: 5.594117647058823 seconds\n",
      "49.csv: 21.428571428571427 seconds\n",
      "50.csv: 21.428571428571427 seconds\n",
      "51.csv: 11.0 seconds\n",
      "54.csv: 5.714285714285714 seconds\n",
      "55.csv: 5.537037037037037 seconds\n",
      "56.csv: 5.537037037037037 seconds\n",
      "58.csv: 21.033898305084747 seconds\n",
      "61.csv: 8.25 seconds\n",
      "63.csv: 10.0 seconds\n",
      "65.csv: 16.5 seconds\n",
      "67.csv: 10.8 seconds\n",
      "70.csv: 20.4 seconds\n",
      "71.csv: Insufficient data for interval calculation seconds\n",
      "78.csv: 5.0 seconds\n",
      "8.csv: 5.473684210526316 seconds\n",
      "99.csv: 10.272727272727273 seconds\n",
      "\n",
      "Overall average sampling interval across all files: 12.476608206381794 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Specify the directory containing your CSV files\n",
    "directory_path = 'C:\\\\Users\\\\ss6365\\\\Desktop\\\\Datasets\\\\UCI\\\\gps\\\\dataset_processed'  # Update this path\n",
    "\n",
    "# Initialize a list to store the results\n",
    "average_intervals = []\n",
    "\n",
    "# Sum of all average intervals\n",
    "total_average_interval = 0\n",
    "\n",
    "# Count of files processed for the overall average calculation\n",
    "file_count = 0\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for file_name in os.listdir(directory_path):\n",
    "    # Check if the file is a CSV\n",
    "    if file_name.endswith('.csv'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        \n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Convert the 'time' column to datetime\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        \n",
    "        # Ensure the data is sorted by 'time'\n",
    "        df = df.sort_values(by='time')\n",
    "        \n",
    "        # Calculate differences (intervals) between each timestamp\n",
    "        df['sampling_interval_seconds'] = df['time'].diff().dt.total_seconds()\n",
    "        \n",
    "        # Ignore NaN values for the average calculation\n",
    "        valid_intervals = df['sampling_interval_seconds'].dropna()\n",
    "        \n",
    "        if not valid_intervals.empty:\n",
    "            # Calculate the average sampling interval\n",
    "            average_sampling_interval = valid_intervals.mean()\n",
    "            \n",
    "            # Add the result to the list for individual file averages\n",
    "            average_intervals.append((file_name, average_sampling_interval))\n",
    "            \n",
    "            # Update the total average and file count\n",
    "            total_average_interval += average_sampling_interval\n",
    "            file_count += 1\n",
    "        else:\n",
    "            # Handle files with insufficient data for interval calculation\n",
    "            average_intervals.append((file_name, 'Insufficient data for interval calculation'))\n",
    "\n",
    "# Calculate the overall average sampling interval across all files\n",
    "overall_average_interval = total_average_interval / file_count if file_count > 0 else 'No valid data found in any file'\n",
    "\n",
    "# Print the list of average sampling intervals for each file\n",
    "for file_name, interval in average_intervals:\n",
    "    print(f\"{file_name}: {interval} seconds\")\n",
    "\n",
    "# Print the overall average sampling interval\n",
    "print(f\"\\nOverall average sampling interval across all files: {overall_average_interval} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d4a0158-8064-4c4c-b51d-197eab822291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column renamed in 1.csv\n",
      "Column renamed in 10.csv\n",
      "Column renamed in 11.csv\n",
      "Column renamed in 12.csv\n",
      "Column renamed in 128.csv\n",
      "Column renamed in 13.csv\n",
      "Column renamed in 131.csv\n",
      "Column renamed in 132.csv\n",
      "Column renamed in 133.csv\n",
      "Column renamed in 134.csv\n",
      "Column renamed in 135.csv\n",
      "Column renamed in 136.csv\n",
      "Column renamed in 137.csv\n",
      "Column renamed in 138.csv\n",
      "Column renamed in 139.csv\n",
      "Column renamed in 14.csv\n",
      "Column renamed in 140.csv\n",
      "Column renamed in 141.csv\n",
      "Column renamed in 142.csv\n",
      "Column renamed in 143.csv\n",
      "Column renamed in 145.csv\n",
      "Column renamed in 146.csv\n",
      "Column renamed in 147.csv\n",
      "Column renamed in 148.csv\n",
      "Column renamed in 149.csv\n",
      "Column renamed in 150.csv\n",
      "Column renamed in 151.csv\n",
      "Column renamed in 153.csv\n",
      "Column renamed in 155.csv\n",
      "Column renamed in 156.csv\n",
      "Column renamed in 157.csv\n",
      "Column renamed in 158.csv\n",
      "Column renamed in 159.csv\n",
      "Column renamed in 16.csv\n",
      "Column renamed in 17.csv\n",
      "Column renamed in 171.csv\n",
      "Column renamed in 173.csv\n",
      "Column renamed in 177.csv\n",
      "Column renamed in 179.csv\n",
      "Column renamed in 18.csv\n",
      "Column renamed in 180.csv\n",
      "Column renamed in 19.csv\n",
      "Column renamed in 190.csv\n",
      "Column renamed in 2.csv\n",
      "Column renamed in 20.csv\n",
      "Column renamed in 205.csv\n",
      "Column renamed in 206.csv\n",
      "Column renamed in 207.csv\n",
      "Column renamed in 208.csv\n",
      "Column renamed in 209.csv\n",
      "Column renamed in 21.csv\n",
      "Column renamed in 210.csv\n",
      "Column renamed in 22.csv\n",
      "Column renamed in 23.csv\n",
      "Column renamed in 24.csv\n",
      "Column renamed in 248.csv\n",
      "Column renamed in 25.csv\n",
      "Column renamed in 26.csv\n",
      "Column renamed in 27.csv\n",
      "Column renamed in 28.csv\n",
      "Column renamed in 3.csv\n",
      "Column renamed in 30.csv\n",
      "Column renamed in 31.csv\n",
      "Column renamed in 32446.csv\n",
      "Column renamed in 32447.csv\n",
      "Column renamed in 33.csv\n",
      "Column renamed in 34.csv\n",
      "Column renamed in 35.csv\n",
      "Column renamed in 36.csv\n",
      "Column renamed in 37.csv\n",
      "Column renamed in 37945.csv\n",
      "Column renamed in 37949.csv\n",
      "Column renamed in 37950.csv\n",
      "Column renamed in 37951.csv\n",
      "Column renamed in 37953.csv\n",
      "Column renamed in 37954.csv\n",
      "Column renamed in 37955.csv\n",
      "Column renamed in 37956.csv\n",
      "Column renamed in 37957.csv\n",
      "Column renamed in 37960.csv\n",
      "Column renamed in 37961.csv\n",
      "Column renamed in 37962.csv\n",
      "Column renamed in 37964.csv\n",
      "Column renamed in 37965.csv\n",
      "Column renamed in 37967.csv\n",
      "Column renamed in 37969.csv\n",
      "Column renamed in 37971.csv\n",
      "Column renamed in 37972.csv\n",
      "Column renamed in 37973.csv\n",
      "Column renamed in 37979.csv\n",
      "Column renamed in 37982.csv\n",
      "Column renamed in 37983.csv\n",
      "Column renamed in 37989.csv\n",
      "Column renamed in 37990.csv\n",
      "Column renamed in 37992.csv\n",
      "Column renamed in 37993.csv\n",
      "Column renamed in 37995.csv\n",
      "Column renamed in 37996.csv\n",
      "Column renamed in 37997.csv\n",
      "Column renamed in 37998.csv\n",
      "Column renamed in 38.csv\n",
      "Column renamed in 38000.csv\n",
      "Column renamed in 38001.csv\n",
      "Column renamed in 38002.csv\n",
      "Column renamed in 38003.csv\n",
      "Column renamed in 38012.csv\n",
      "Column renamed in 38013.csv\n",
      "Column renamed in 38015.csv\n",
      "Column renamed in 38016.csv\n",
      "Column renamed in 38017.csv\n",
      "Column renamed in 38018.csv\n",
      "Column renamed in 38019.csv\n",
      "Column renamed in 38020.csv\n",
      "Column renamed in 38021.csv\n",
      "Column renamed in 38022.csv\n",
      "Column renamed in 38024.csv\n",
      "Column renamed in 38030.csv\n",
      "Column renamed in 38031.csv\n",
      "Column renamed in 38039.csv\n",
      "Column renamed in 38044.csv\n",
      "Column renamed in 38045.csv\n",
      "Column renamed in 38064.csv\n",
      "Column renamed in 38069.csv\n",
      "Column renamed in 38072.csv\n",
      "Column renamed in 38073.csv\n",
      "Column renamed in 38074.csv\n",
      "Column renamed in 38075.csv\n",
      "Column renamed in 38076.csv\n",
      "Column renamed in 38077.csv\n",
      "Column renamed in 38079.csv\n",
      "Column renamed in 38080.csv\n",
      "Column renamed in 38081.csv\n",
      "Column renamed in 38082.csv\n",
      "Column renamed in 38084.csv\n",
      "Column renamed in 38090.csv\n",
      "Column renamed in 38092.csv\n",
      "Column renamed in 39.csv\n",
      "Column renamed in 4.csv\n",
      "Column renamed in 40.csv\n",
      "Column renamed in 41.csv\n",
      "Column renamed in 42.csv\n",
      "Column renamed in 43.csv\n",
      "Column renamed in 44.csv\n",
      "Column renamed in 45.csv\n",
      "Column renamed in 46.csv\n",
      "Column renamed in 47.csv\n",
      "Column renamed in 48.csv\n",
      "Column renamed in 49.csv\n",
      "Column renamed in 50.csv\n",
      "Column renamed in 51.csv\n",
      "Column renamed in 54.csv\n",
      "Column renamed in 55.csv\n",
      "Column renamed in 56.csv\n",
      "Column renamed in 58.csv\n",
      "Column renamed in 61.csv\n",
      "Column renamed in 63.csv\n",
      "Column renamed in 65.csv\n",
      "Column renamed in 67.csv\n",
      "Column renamed in 70.csv\n",
      "Column renamed in 71.csv\n",
      "Column renamed in 78.csv\n",
      "Column renamed in 8.csv\n",
      "Column renamed in 99.csv\n",
      "Done processing all files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the directory containing your CSV files\n",
    "directory_path = 'C:\\\\Users\\\\ss6365\\\\Desktop\\\\Datasets\\\\UCI\\\\gps\\\\dataset_processed'  # Update this path to your directory\n",
    "\n",
    "# Column names\n",
    "old_column_name = 'track_id'  # The original name of the column you want to rename\n",
    "new_column_name = 'identifier'  # The new name for the column\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for file_name in os.listdir(directory_path):\n",
    "    # Check if the file is a CSV\n",
    "    if file_name.endswith('.csv'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        \n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Check if the column to be renamed exists in the DataFrame\n",
    "        if old_column_name in df.columns:\n",
    "            # Rename the column\n",
    "            df.rename(columns={old_column_name: new_column_name}, inplace=True)\n",
    "            \n",
    "            # Save the modified DataFrame back to the CSV, overwriting the original file\n",
    "            df.to_csv(file_path, index=False)\n",
    "            print(f\"Column renamed in {file_name}\")\n",
    "        else:\n",
    "            print(f\"Column '{old_column_name}' not found in {file_name}\")\n",
    "\n",
    "print(\"Done processing all files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d1374a-276f-42c7-adf5-680ca9d7cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############# Data Security ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "742d43cf-0cd4-468b-ac38-7ab446805997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV file saved to C:\\Users\\ss6365\\Desktop\\location_privacy_final\\uci\\data\\merged_all_utility_subset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Input directory containing CSV files\n",
    "input_directory = 'C:\\\\Users\\\\ss6365\\\\Desktop\\\\location_privacy_final\\\\uci\\\\data\\\\utility'\n",
    "\n",
    "# Output directory where the merged CSV file will be saved\n",
    "output_directory = 'C:\\\\Users\\\\ss6365\\\\Desktop\\\\location_privacy_final\\\\uci\\\\data'\n",
    "\n",
    "\n",
    "\n",
    "# # List of important columns to keep\n",
    "important_columns = ['identifier', 'longitude', 'latitude']  # Replace with your column names\n",
    "\n",
    "# # Create a list to store dataframes from individual CSV files\n",
    "dataframes = []\n",
    "\n",
    "# # Iterate through CSV files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        df = pd.read_csv(file_path, usecols=important_columns)\n",
    "        dataframes.append(df)\n",
    "\n",
    "# # Concatenate dataframes vertically (along rows)\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# # Output file path for the merged CSV file\n",
    "output_file_path = os.path.join(output_directory, 'merged_all_utility_subset.csv')\n",
    "\n",
    "# # Save the merged dataframe to a CSV file\n",
    "merged_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Merged CSV file saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac32e5df-db79-4fe4-9b09-d7eeba0b3c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.939341</td>\n",
       "      <td>-37.062742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.939341</td>\n",
       "      <td>-37.062742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.939324</td>\n",
       "      <td>-37.062765</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.939211</td>\n",
       "      <td>-37.062843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10.938939</td>\n",
       "      <td>-37.062879</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>-10.925716</td>\n",
       "      <td>-37.075154</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18000</th>\n",
       "      <td>-10.925418</td>\n",
       "      <td>-37.076027</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18001</th>\n",
       "      <td>-10.925417</td>\n",
       "      <td>-37.076027</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18002</th>\n",
       "      <td>-10.925418</td>\n",
       "      <td>-37.076027</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18003</th>\n",
       "      <td>-10.925435</td>\n",
       "      <td>-37.076129</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5434 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        latitude  longitude  identifier\n",
       "0     -10.939341 -37.062742           1\n",
       "1     -10.939341 -37.062742           1\n",
       "2     -10.939324 -37.062765           1\n",
       "3     -10.939211 -37.062843           1\n",
       "4     -10.938939 -37.062879           1\n",
       "...          ...        ...         ...\n",
       "17999 -10.925716 -37.075154          58\n",
       "18000 -10.925418 -37.076027          58\n",
       "18001 -10.925417 -37.076027          58\n",
       "18002 -10.925418 -37.076027          58\n",
       "18003 -10.925435 -37.076129          58\n",
       "\n",
       "[5434 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\ss6365\\Desktop\\location_privacy_final\\uci\\data\\merged_all_utility_subset.csv')\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Radius of the Earth in km\n",
    "    R = 6371.0\n",
    "    # Convert coordinates from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "def find_square_boundaries(lat, lon, distance_km):\n",
    "    # Approximate conversions\n",
    "    delta_lat = distance_km / 111  # 111 km per degree of latitude\n",
    "    delta_lon = distance_km / (111 * np.cos(np.radians(lat)))  # Adjust for longitude\n",
    "    return lat - delta_lat, lat + delta_lat, lon - delta_lon, lon + delta_lon\n",
    "\n",
    "\n",
    "# Calculate the median (or mean) latitude and longitude\n",
    "central_lat = df['latitude'].median()\n",
    "central_lon = df['longitude'].median()\n",
    "\n",
    "\n",
    "# Define the square region boundaries\n",
    "lat_min, lat_max, lon_min, lon_max = find_square_boundaries(central_lat, central_lon, 2)\n",
    "\n",
    "# Filter the DataFrame for points within the 1 km square\n",
    "df_limit = df[(df['latitude'] >= lat_min) & (df['latitude'] <= lat_max) &\n",
    "               (df['longitude'] >= lon_min) & (df['longitude'] <= lon_max)]\n",
    "\n",
    "df_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2012c6bd-ceb8-406f-b8f8-43201bceb709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Input and output directories\n",
    "input_directory = r'C:\\Users\\ss6365\\Desktop\\location_privacy_final\\uci\\data\\utility'\n",
    "output_directory = r'C:\\Users\\ss6365\\Desktop\\location_privacy_final\\uci\\data\\security'\n",
    "\n",
    "\n",
    "# Calculate the boundaries based on the current file\n",
    "lat_min = df_limit['latitude'].min()\n",
    "lat_max = df_limit['latitude'].max()\n",
    "lon_min = df_limit['longitude'].min()\n",
    "lon_max = df_limit['longitude'].max()\n",
    "\n",
    "\n",
    "# Iterate through CSV files in the input directory\n",
    "for csv_file in glob.glob(os.path.join(input_directory, '*.csv')):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "\n",
    "\n",
    "    # Distance parameter (can be adjusted as needed)\n",
    "    distance_km = 2\n",
    "\n",
    "    # Define the square region boundaries and filter the DataFrame\n",
    "    df_square = df[(df['latitude'] >= lat_min) & (df['latitude'] <= lat_max) &\n",
    "                   (df['longitude'] >= lon_min) & (df['longitude'] <= lon_max)]\n",
    "\n",
    "    # Check if the filtered DataFrame is empty (no data within boundaries)\n",
    "    if df_square.empty:\n",
    "        continue  # Skip saving if no data matches the criteria\n",
    "\n",
    "    # Extract the base filename without extension\n",
    "    base_filename = os.path.splitext(os.path.basename(csv_file))[0]\n",
    "    \n",
    "    # Create the new filename with distance_km\n",
    "    new_filename = f\"{base_filename}_{distance_km}km.csv\"\n",
    "    \n",
    "    # Save the filtered DataFrame to the output directory with the new filename\n",
    "    output_path = os.path.join(output_directory, new_filename)\n",
    "    df_square.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d687ddf-c047-4ff3-8c47-7b2d6db0f6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
